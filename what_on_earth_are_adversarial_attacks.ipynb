{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RoTjOwleYHzb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import  cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7fayUwbiYg_p"
   },
   "source": [
    "# The primary idea is to maximise the loss on a certain image with minimal modifications \n",
    "\n",
    "## But for that we first have to know how does a model minimize loss first\n",
    "\n",
    "* Learning step 1 - The raw image is passed through the model, and it returns a label accordingly (`pred`)\n",
    "* Learning step 2 - The `pred` is then compared with the original `label` and a certain \"difference\" which is calculated with a fancy mathematical function depending upon the task at hand. \n",
    "> In our case it's `nn.CrossEntropyLoss()` because it's a classification  problem\n",
    "* Learning step 3 - the weights are adjusted in the network based on the backropagated gradients\n",
    "> The *change in the loss* for a *small change in an input weight* is called the gradient of that weight and is calculated using *backpropagation*  \n",
    "\n",
    "$$gradient = \\frac{\\partial (loss)}{\\partial (weight)}$$\n",
    "\n",
    "Now in the normal learning process, the weights are adjusted with respect to the gradient in order to minimise loss.\n",
    "\n",
    "But our objective is to maximise loss, and the key to that is **extracting the gradient**\n",
    "\n",
    "\n",
    "\n",
    "> `empty_tensor.random_(x)` returns a a random distribution ranged from 0 to x-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "-h9dJsXgZR4O",
    "outputId": "5c291fa4-24b5-417c-c862-d8bc1065da76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted probability distribution of classes =  [1.0, 0.0]\n",
      "actual index of class =  0\n",
      "loss =  tensor(0.3133, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# loss func\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "## prediction\n",
    "pred = torch.tensor([[1., 0.]], requires_grad=True)\n",
    "\n",
    "## generate a random index either  (0 or 1) as the label\n",
    "label = torch.empty(1, dtype=torch.long).random_(2)  ## \n",
    "\n",
    "## calculating the loss val \n",
    "oof = loss(pred, label)\n",
    "\n",
    "print(\"predicted probability distribution of classes = \", pred.flatten().tolist())\n",
    "print(\"actual index of class = \",label.item())\n",
    "print(\"loss = \", oof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  For our experiments, I'll use a pre trained model trained to classify animals from Minecraft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "caOODlmpm2I8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 7, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (conv2): Conv2d(7, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (fc2): Linear(in_features=10, out_features=8, bias=True)\n",
       "  (fc3): Linear(in_features=8, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 7, 5)\n",
    "        self.pool = nn.MaxPool2d(3, 3)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.conv2 = nn.Conv2d(7, 10, 5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(10, 10)\n",
    "        self.fc2 = nn.Linear(10, 8)\n",
    "        self.fc3 = nn.Linear(8, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "hunter = Net()\n",
    "hunter.zero_grad()\n",
    "hunter.load_state_dict(torch.load(\"hunter.pt\"))\n",
    "hunter.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading up a sample image and checking the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_for_model(img_path):\n",
    "    im = cv2.imread(\"images/chicken.png\")\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)  # convert to RGB color space \n",
    "    plt.imshow(im)\n",
    "    im_moveaxis =  np.moveaxis(im, 2, 0) \n",
    "    input_tensor =  torch.from_numpy(im_moveaxis).unsqueeze(0).float()\n",
    "    return input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label =  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_tensor = preprocess_image_for_model(\"images/chicken.png\")\n",
    "print (\"Predicted label = \", torch.argmax(hunter(input_tensor)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  9.727005090098828e-05\n"
     ]
    }
   ],
   "source": [
    "label = torch.zeros(1, dtype=torch.long)  ##\n",
    "input_tensor.requires_grad = True\n",
    "pred = hunter(input_tensor)\n",
    "loss_val = loss(pred,label)\n",
    "print(\"loss = \",loss_val.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_val.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grad = input_tensor.grad.data"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "what_on_earth_are_adversrial_attacks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
